{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RonakArora09/Face-Image-Generator/blob/main/Face_Image_Generator_DCGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **FACE IMAGES GENERATOR USING DEEP CONVOLUTIONAL GENERATIVE ADVERSARIAL NETWORK (DCGAN)**\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "OZO90Gzqmx2O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generative Adversarial Network, invented by Ian Goodfellowin in 2014, is one of the coolest technique in Deep Learning. It is an unsupervised algorithm used for Generative modelling. Deep Convolutional GAN (DCGAN) is one of the first branch of GANs which is used for creating new fake images which are in-distinguishable from the original ones.\n",
        "\n",
        "The technique uses two competing networks, namely **Discriminator** and **Generator**. The Discriminator's job is to classify whether the given image is real or artificial. The Generator task is to generate images to fool Discriminator to believe that the image generated by it is real."
      ],
      "metadata": {
        "id": "1f1_Uf_KnPko"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> We are using CelebA dataset available from https://mmlab.ie.cuhk.edu.hk/projects/CelebA.html to train this model. The zip file of the dataset is stored on the drive folder and is extracted in the colab working directory to train the model.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "qoHY6CtfvkxX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_hxMMeQMbF84"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import sys\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IzJNueLXDag9"
      },
      "outputs": [],
      "source": [
        "!unzip /content/drive/MyDrive/img_align_celeba.zip -d /tmp/celebA"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Parameters used in the model:\n",
        "\n",
        "**batch_size**  : Number of training images used per model update\n",
        "\n",
        "**image_dim**   : Shape of the training images\n",
        "\n",
        "**latent_dim**  : Length of noise input to the generator\n"
      ],
      "metadata": {
        "id": "7p5I97mexqau"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KsoFGkbjV6hv"
      },
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "image_dim  = (64,64)\n",
        "latent_dim = 100"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Discriminator Model"
      ],
      "metadata": {
        "id": "UH9BPQbV5PSu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z6uvTQVIjg5q"
      },
      "outputs": [],
      "source": [
        "def make_discriminator_model():\n",
        "    model = keras.models.Sequential()\n",
        "    \n",
        "    model.add(keras.layers.Lambda(lambda x: (x-127.5)/127.5))\n",
        "\n",
        "    model.add(keras.layers.Conv2D(64, (4,4), strides=(2,2), use_bias=False, input_shape = (64,64,3),kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.02)))\n",
        "    model.add(keras.layers.LeakyReLU(0.2))\n",
        "    model.add(keras.layers.Dropout(0.3))\n",
        "\n",
        "    model.add(keras.layers.Conv2D(128, (4,4), strides=(2,2), use_bias=False,kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.02)))\n",
        "    model.add(keras.layers.BatchNormalization())\n",
        "    model.add(keras.layers.LeakyReLU(0.2))\n",
        "    model.add(keras.layers.Dropout(0.3))\n",
        "\n",
        "    model.add(keras.layers.Conv2D(256, (4,4), strides=(2,2), use_bias=False,kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.02)))\n",
        "    model.add(keras.layers.BatchNormalization())\n",
        "    model.add(keras.layers.LeakyReLU(0.2))\n",
        "    model.add(keras.layers.Dropout(0.3))\n",
        "\n",
        "    model.add(keras.layers.Conv2D(512, (4,4), strides=(2,2), use_bias=False,kernel_initializer=tf.keras.initializers.RandomNormal(mean = 0, stddev=0.02)))\n",
        "    model.add(keras.layers.BatchNormalization())\n",
        "    model.add(keras.layers.LeakyReLU(0.2))\n",
        "    model.add(keras.layers.Dropout(0.3))\n",
        "\n",
        "    model.add(keras.layers.Flatten())\n",
        "    model.add(keras.layers.Dense(1, activation=tf.nn.sigmoid, use_bias=False,))\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generator Model"
      ],
      "metadata": {
        "id": "RYWowVFY5Y9H"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0-g5WnbvVNSi"
      },
      "outputs": [],
      "source": [
        "def make_generator_model(latent_dim, noise):\n",
        "\n",
        "    model = tf.keras.Sequential()\n",
        "\n",
        "    model.add(keras.layers.Dense(4*4*1024, use_bias=False, input_shape=(latent_dim,)))\n",
        "    model.add(keras.layers.BatchNormalization())\n",
        "    model.add(keras.layers.ReLU())\n",
        "\n",
        "    model.add(keras.layers.Reshape((4, 4, 1024)))\n",
        "\n",
        "    model.add(keras.layers.Conv2DTranspose(512, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
        "    model.add(keras.layers.BatchNormalization())\n",
        "    model.add(keras.layers.ReLU())\n",
        "\n",
        "    model.add(keras.layers.Conv2DTranspose(256, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
        "    model.add(keras.layers.BatchNormalization())\n",
        "    model.add(keras.layers.ReLU())\n",
        "\n",
        "    model.add(keras.layers.Conv2DTranspose(128, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
        "    model.add(keras.layers.BatchNormalization())\n",
        "    model.add(keras.layers.ReLU())\n",
        "\n",
        "    model.add(keras.layers.Conv2DTranspose(3, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\n",
        "    model.add(keras.layers.Lambda(lambda x: x*127.5 + 127.5))\n",
        "\n",
        "    model.noise = noise\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **DCGAN Model**"
      ],
      "metadata": {
        "id": "1pLXUaCLX3UC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c3moW-hteBK1"
      },
      "outputs": [],
      "source": [
        "class DCGAN(tf.keras.Model):\n",
        "    def __init__(self, discriminator = None, generator = None, batch_size = 64, image_dim = (64,64), latent_dim = 128):\n",
        "        super(DCGAN,self).__init__()\n",
        "\n",
        "        self.batch_size = batch_size\n",
        "        self.image_dim  = image_dim\n",
        "        self.latent_dim = latent_dim\n",
        "        self.discriminator = discriminator\n",
        "        self.generator = generator\n",
        "\n",
        "    def load_images(self, images_path):\n",
        "        images_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "            images_path,\n",
        "            labels = None,\n",
        "            image_size = self.image_dim,\n",
        "            batch_size = self.batch_size)\n",
        "        self.images_ds = images_ds\n",
        "\n",
        "    def save_current_state(self):\n",
        "        self.discriminator.save('/content/drive/MyDrive/DCGAN/discriminator')\n",
        "        self.generator.save('/content/drive/MyDrive/DCGAN/generator')\n",
        "\n",
        "    def load_models(self):\n",
        "        discriminator = tf.keras.models.load_model('/content/drive/MyDrive/DCGAN/discriminator')\n",
        "        generator = tf.keras.models.load_model('/content/drive/MyDrive/DCGAN/generator')\n",
        "        self.discriminator =  discriminator\n",
        "        self.generator = generator\n",
        "\n",
        "    def compile(self, discriminator_optimizer, generator_optimizer, loss_fn, images_path, **kwargs):\n",
        "        super().compile(**kwargs)\n",
        "\n",
        "        self.discriminator_optimizer = discriminator_optimizer\n",
        "        self.generator_optimizer = generator_optimizer\n",
        "        self.loss_fn = loss_fn\n",
        "        self.load_images(images_path)\n",
        "\n",
        "        if(not self.discriminator):\n",
        "            self.load_models()\n",
        "\n",
        "    def discriminator_loss(self, real_output, fake_output):\n",
        "        real_loss = self.loss_fn(np.ones_like(real_output),real_output)\n",
        "        fake_loss = self.loss_fn(np.zeros_like(fake_output),fake_output)\n",
        "        discriminator_loss = real_loss + fake_loss\n",
        "        return discriminator_loss\n",
        "\n",
        "    def generator_loss(self, fake_output):\n",
        "        generator_loss = self.loss_fn(np.ones_like(fake_output), fake_output)\n",
        "        return generator_loss\n",
        "\n",
        "    def callback(self):\n",
        "        fake_images = self.generator(self.generator.noise)\n",
        "        fig = plt.figure(figsize=(16,16))\n",
        "        plt.axis(\"off\")\n",
        "        plt.title(\"These people do not exist\")\n",
        "        for i in range(32):\n",
        "            sub = fig.add_subplot(8, 4, i + 1)\n",
        "            sub.axis(\"off\")\n",
        "            sub.imshow(fake_images.numpy()[i].astype(np.uint8))\n",
        "        plt.show()\n",
        "        self.save_current_state()\n",
        "    \n",
        "\n",
        "    def train_step(self, real_images):\n",
        "        with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "\n",
        "            fake_images = self.generator(self.generator.noise)\n",
        "\n",
        "            real_output = self.discriminator(real_images)\n",
        "            fake_output = self.discriminator(fake_images)\n",
        "\n",
        "            disc_loss = self.discriminator_loss(real_output, fake_output)\n",
        "            gen_loss = self.generator_loss(fake_output)\n",
        "        \n",
        "        disc_grad = disc_tape.gradient(disc_loss, self.discriminator.trainable_variables)\n",
        "        self.discriminator_optimizer.apply_gradients(zip(disc_grad, self.discriminator.trainable_variables))\n",
        "\n",
        "        gen_grad = gen_tape.gradient(gen_loss, self.generator.trainable_variables)\n",
        "        self.generator_optimizer.apply_gradients(zip(gen_grad, self.generator.trainable_variables))\n",
        "\n",
        "        return disc_loss, gen_loss\n",
        "\n",
        "    def train(self, epochs = 5):\n",
        "\n",
        "        iter = 0\n",
        "        for epoch in range(epochs):\n",
        "            for real_images in self.images_ds:\n",
        "\n",
        "                disc_loss, gen_loss = self.train_step(real_images)\n",
        "                sys.stdout.write(f\"\\r{iter} >>>> disc_loss: {disc_loss:5e},   gen_loss: {gen_loss:5e}\")\n",
        "                \n",
        "                if(iter%500 == 0):\n",
        "                    self.callback()\n",
        "                iter += 1\n",
        "            "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "noise = np.array([np.random.normal(size=latent_dim) for _ in range(batch_size)])\n",
        "discriminator = make_discriminator_model()\n",
        "generator = make_generator_model(latent_dim, noise)\n",
        "model = DCGAN(discriminator, generator, batch_size=batch_size, image_dim=image_dim, latent_dim=latent_dim)"
      ],
      "metadata": {
        "id": "7ZdOKTlJDvSy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If no discriminator, generator model given, the model laods the saved models from google drive."
      ],
      "metadata": {
        "id": "j2WyFJbeYAAs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = DCGAN()"
      ],
      "metadata": {
        "id": "hymQSarQFIZM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "discriminator_optimizer = keras.optimizers.RMSprop(learning_rate = 1e-4)\n",
        "generator_optimizer = keras.optimizers.RMSprop(learning_rate = 1e-4)\n",
        "loss_fn = tf.keras.losses.BinaryCrossentropy()\n",
        "images_path = \"/tmp/celebA/img_align_celeba/\"\n",
        "\n",
        "model.compile(discriminator_optimizer, generator_optimizer, loss_fn, images_path)"
      ],
      "metadata": {
        "id": "EQ5EF_cVBmAf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "noise = np.array([np.random.normal(size=latent_dim) for _ in range(batch_size)])\n",
        "model.generator.noise = noise"
      ],
      "metadata": {
        "id": "PQ_MaE7Bnx13"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.train()"
      ],
      "metadata": {
        "id": "jhjTrcUoBwPh"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Face_Image_Generator_DCGAN.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}